# streamlit_app.py â€” drop expander, always visible instructions
"""
ğŸ“ Text Transformation App â€“ Streamlit
-------------------------------------
Changes in this patch:

* **Removed** the collapsible expander. The Howâ€‘to section now shows by default.
* No other behaviour changed.
"""

from io import StringIO
import json
import re

import pandas as pd
import streamlit as st

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Page setâ€‘up  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="Text Transformation App",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Inject CSS for centred hero + compact padding
st.markdown(
    """
    <style>
        /* â”€â”€â”€ Hero title â”€â”€â”€ */
        .block-container h1:first-child {
            text-align: center;
            font-size: 3rem;
            font-weight: 800;
            margin-bottom: 1.25rem;
        }
        /* â”€â”€â”€ Compact top padding â”€â”€â”€ */
        .block-container { padding-top: 1.2rem; }
        /* â”€â”€â”€ Sidebar header size â”€â”€â”€ */
        section[data-testid="stSidebar"] h2 {
            font-size: 1.05rem; margin-bottom: .3rem;
        }
    </style>
    """,
    unsafe_allow_html=True,
)

st.title("ğŸ“ Text Transformation App")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Default dictionary  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_DICT = {
    "Fashion": ["style", "fashion", "wardrobe", "clothing", "outfit"],
    "Food": ["delicious", "food", "dinner", "lunch", "restaurant"],
    "Travel": ["travel", "trip", "vacation", "explore", "journey"],
    "Fitness": ["workout", "fitness", "exercise", "gym", "training"],
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Sidebar  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## 1ï¸âƒ£Â Â Upload
st.sidebar.header("1ï¸âƒ£Â Â Upload your CSV")
uploaded_file = st.sidebar.file_uploader(
    "Choose an Instagram CSV file (â‰¤200â€¯MB)",
    type=["csv"],
    accept_multiple_files=False,
)

st.sidebar.markdown("---")

## 2ï¸âƒ£Â Â Dictionary
st.sidebar.header("2ï¸âƒ£Â Â Modify keyword dictionary")

dict_input = st.sidebar.text_area(
    "Dictionary (JSON)",
    value=json.dumps(DEFAULT_DICT, indent=2),
    height=280,
)

try:
    keyword_dict = json.loads(dict_input)
    if not isinstance(keyword_dict, dict):
        raise ValueError("Dictionary root must be a JSON object (key â†’ list).")
except (json.JSONDecodeError, ValueError) as e:
    st.sidebar.error(f"âŒ {e}\nUsing default dictionary instead.")
    keyword_dict = DEFAULT_DICT

st.sidebar.markdown(
    """<small>ğŸ”§â€¯Edit the JSON above to add/delete categories & keywords.</small>""",
    unsafe_allow_html=True,
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Helper functions  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def classify_sentence(text: str, kw_dict: dict) -> str:
    """Return first category whose keywords appear in *text* (caseâ€‘insensitive)."""
    text_lower = text.lower()
    for cat, kws in kw_dict.items():
        if any(k.lower() in text_lower for k in kws):
            return cat
    return "Uncategorized"


def process_dataframe(df: pd.DataFrame, kw_dict: dict) -> pd.DataFrame:
    """Split captions into sentences/hashtags âœ classify âœ tidy DataFrame."""
    df = df.rename(columns={"shortcode": "ID", "caption": "Context"})
    rows = []
    for _, row in df.iterrows():
        # split on sentence terminators **or** lookâ€‘ahead for a hashtag
        sentences = re.split(r"(?<=[.!?])\s+|(?=#[^\s]+)", str(row["Context"]))
        for i, s in enumerate(sentences, start=1):
            clean = re.sub(r"\s+", " ", s.strip())
            if clean and not re.fullmatch(r"[.!?]+", clean):
                rows.append(
                    {
                        "ID": row["ID"],
                        "Context": row["Context"],
                        "Sentence ID": i,
                        "Statement": clean,
                        "Category": classify_sentence(clean, keyword_dict),
                    }
                )
    return pd.DataFrame(rows)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  How to Use  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.markdown(
    """
### How to Use
1. **Upload your CSV file** using the file uploader above  
2. **Select ID Column** â€“ Choose the column that uniquely identifies each record  
3. **Select Context Column** â€“ Choose the column containing the text to be transformed  
4. **Configure options** â€“ Choose whether to include hashtags as separate sentences  
5. **Click _Transform_** â€“ Process your data into sentenceâ€‘level format  
6. **Download results** â€“ Get your transformed data as a CSV file  

### Output Format
The transformed data will have the following columns:

- **ID**: The identifier from your selected ID column  
- **Sentence ID**: Sequential number for each sentence within a record  
- **Context**: The original text from your Context column  
- **Statement**: Individual sentences extracted from the context  
    """
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Main logic  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if uploaded_file is None:
    st.info("ğŸ‘ˆÂ Â Start by uploading a CSV file from the sidebar.")
    st.stop()

raw_df = pd.read_csv(uploaded_file)

if not {"shortcode", "caption"}.issubset(raw_df.columns):
    st.error("CSV must contain `shortcode` and `caption` columns.")
    st.stop()

if st.sidebar.button("âš™ï¸Â Â Transform"):
    with st.spinner("Processing â€¦"):
        final_df = process_dataframe(raw_df, keyword_dict)

    st.success("Processing complete!")
    st.subheader("Preview of processed data")
    st.dataframe(final_df, use_container_width=True)

    buff = StringIO()
    final_df.to_csv(buff, index=False)
    st.download_button(
        "ğŸ’¾Â Â Download CSV",
        data=buff.getvalue(),
        mime="text/csv",
        file_name="transformed_text.csv",
    )


